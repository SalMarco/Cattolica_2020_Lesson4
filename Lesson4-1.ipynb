{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Introduction to Python\n",
    "================================\n",
    "\n",
    "Lesson 4 - Part1\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson we will focus on Neural Network. The lesson is divided between an introduction an a technical part\n",
    "The topis that we'll cover are in the introduction are:\n",
    "\n",
    "  - Tensorflow\n",
    "  - Keras \n",
    "  \n",
    "For the technical part we will create some models for:\n",
    "\n",
    "  - Single class classification\n",
    "  - Multi class classification\n",
    "  - Custom model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Today there are many framework that allow to create a Neural Network, like:\n",
    "\n",
    "  - Tensorflow \n",
    "  - Theano\n",
    "  - Caffe\n",
    "  - MXNett\n",
    "  - CNTK\n",
    "  \n",
    "Among all of them, probabilly the most famous is Tensorflow.\n",
    "\n",
    "Considering the support, the community the resources available, Tensorflow is the engine chosen for this course.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/) it was originally developed by Google, now it's open source.\n",
    "\n",
    "The definition from the web site is the following:\n",
    "\n",
    "*TensorFlow™ is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google’s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains.*\n",
    "\n",
    "Google has deeply invested in this project, to the point that now in Google Cloud there are available some instances with GPU's (called TPU's) designed especially for TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras\n",
    "\n",
    "In order to simply the definition of the Neural Network and to speed up the development time we'll not use TensorFlow directly.\n",
    "Instead we'll use [Keras](https://keras.io/).\n",
    "\n",
    "The definition from the website is the following:\n",
    "\n",
    "*Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "*\n",
    "\n",
    "As you can see from the description, Keras offers another advantage: with just a change of setting the same code can be used with:\n",
    "\n",
    "  - Tensorflow\n",
    "  - Theano\n",
    "  - CNTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 2.0\n",
    "\n",
    "Tensorflow 2.0 has been released on September 30th 2019.\n",
    "\n",
    "The main new feature in this new relese in that Keras' API are now the official High Level APIs of Tensorflow, directly supported by the project itself.\n",
    "\n",
    "Quoting the home page of Keras:\n",
    "\n",
    "*At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to tf.keras in TensorFlow 2.0. tf.keras is better maintained and has better integration with TensorFlow features (eager execution, distribution support and other).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison between Keras and Tensorflow\n",
    "\n",
    "In order to undestand the advantage of using Keras, we will consider the code necessary to define the same network using TensorFlow directly or Keras.\n",
    "\n",
    "Before moving on we must remember what are the parameters involved with a neural network.\n",
    "\n",
    "Can you list me those parameters?\n",
    "\n",
    "  - num imp.\n",
    "  - num. layers\n",
    "  - num. out \n",
    "  - node in layers \n",
    "  - activation \n",
    "  - loss\n",
    "  - optimization\n",
    "  - epoch \n",
    "  - batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensoFlow Multiclass\n",
    "\n",
    "This is an example of how it was to create a neural network using \"pure\" Tensorflow. \n",
    "The dataset used was the classic [mnsit](http://yann.lecun.com/exdb/mnist/) hand written digits with two hidden layer to classify samples in to the 10 possible classes. \n",
    "\n",
    "**NOTE:** this example is not working anymore, due to the changes between Tensorflow v1 and v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples.tutorials'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3d55fec490c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 15\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras Multiclass\n",
    "\n",
    "Let's create a neural network to be used over the classic [mnsit](http://yann.lecun.com/exdb/mnist/) hand written digits with two hidden layer to classify samples in to the 10 possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X, Y), (X_test, Y_test) = mnist.load_data()\n",
    "X, X_test = X / 255.0, X_test / 255.0\n",
    "print(X.shape)\n",
    "x_ex = X[1,:,:]\n",
    "x_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.2874 - accuracy: 0.9175 - val_loss: 0.1078 - val_accuracy: 0.9697\n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.1095 - accuracy: 0.9670 - val_loss: 0.0779 - val_accuracy: 0.9817\n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.0716 - accuracy: 0.9790 - val_loss: 0.0736 - val_accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.0522 - accuracy: 0.9840 - val_loss: 0.0861 - val_accuracy: 0.9763\n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 3s 8ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.0737 - val_accuracy: 0.9810\n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 4s 10ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0737 - val_accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0629 - val_accuracy: 0.9850\n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 4s 9ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0763 - val_accuracy: 0.9817\n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 4s 8ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0774 - val_accuracy: 0.9827\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0824 - accuracy: 0.9767\n",
      "\n",
      "accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras as keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras import advanced_activations\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 100 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "#\n",
    "activationFun = 'relu'\n",
    "#activationFun = 'softmax'\n",
    "\n",
    "tryOverfit = True\n",
    "\n",
    "#Definition of the model type\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(n_hidden_1,activation=activationFun))\n",
    "if tryOverfit:\n",
    "    model.add(Dense(n_hidden_2,activation=activationFun))\n",
    "\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "#Creation of the model\n",
    "adam = Adam(lr=learning_rate)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,metrics=['accuracy'])\n",
    "#Fit of the network\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X, Y), (X_test, Y_test) = mnist.load_data()\n",
    "X, X_test = X / 255.0, X_test / 255.0\n",
    "history = model.fit(X, Y, epochs=num_steps, batch_size=batch_size,validation_split=0.05)#validation_data=(X_test,Y_test)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Warning\n",
    "\n",
    "Keras is an API, so the implementation of function is not one to one with TensorFlow. Often similar parameters can bring to different results.\n",
    "\n",
    "**You have to optimize the network for Keras, not for Tensorflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis' Results\n",
    "\n",
    "If we take a closer look to the results of the network what we can see?\n",
    "\n",
    "During the fit of the model, with `history = model.fit`, we have stored in `history` all the values of **loss** and **accuracy** for train and test.\n",
    "\n",
    "Note that must pass some validation data or a validation split using `validation_data` or `validation_split` parameters in `model.fit` \n",
    "\n",
    "We can define these and other metrics to be use using the parameter `metrics` in `model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.315448</td>\n",
       "      <td>0.910193</td>\n",
       "      <td>0.132399</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136765</td>\n",
       "      <td>0.960649</td>\n",
       "      <td>0.087144</td>\n",
       "      <td>0.977667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.091477</td>\n",
       "      <td>0.973842</td>\n",
       "      <td>0.075194</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.067522</td>\n",
       "      <td>0.980193</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0.984333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052308</td>\n",
       "      <td>0.984544</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.980333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041884</td>\n",
       "      <td>0.987456</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032398</td>\n",
       "      <td>0.991193</td>\n",
       "      <td>0.062586</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026082</td>\n",
       "      <td>0.993246</td>\n",
       "      <td>0.058798</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.021145</td>\n",
       "      <td>0.994789</td>\n",
       "      <td>0.063087</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.996140</td>\n",
       "      <td>0.065787</td>\n",
       "      <td>0.982667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.315448  0.910193  0.132399      0.968000\n",
       "1  0.136765  0.960649  0.087144      0.977667\n",
       "2  0.091477  0.973842  0.075194      0.981000\n",
       "3  0.067522  0.980193  0.064990      0.984333\n",
       "4  0.052308  0.984544  0.067981      0.980333\n",
       "5  0.041884  0.987456  0.058200      0.986000\n",
       "6  0.032398  0.991193  0.062586      0.983000\n",
       "7  0.026082  0.993246  0.058798      0.983333\n",
       "8  0.021145  0.994789  0.063087      0.980000\n",
       "9  0.016616  0.996140  0.065787      0.982667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3154478073120117,\n",
       "  0.1367649883031845,\n",
       "  0.0914771780371666,\n",
       "  0.06752198189496994,\n",
       "  0.05230846628546715,\n",
       "  0.041884277015924454,\n",
       "  0.03239814192056656,\n",
       "  0.02608170174062252,\n",
       "  0.021144993603229523,\n",
       "  0.016615744680166245],\n",
       " 'accuracy': [0.9101929664611816,\n",
       "  0.9606491327285767,\n",
       "  0.9738420844078064,\n",
       "  0.9801929593086243,\n",
       "  0.9845438599586487,\n",
       "  0.9874561429023743,\n",
       "  0.9911929965019226,\n",
       "  0.9932456016540527,\n",
       "  0.9947894811630249,\n",
       "  0.9961403608322144],\n",
       " 'val_loss': [0.1323985606431961,\n",
       "  0.0871439278125763,\n",
       "  0.07519359141588211,\n",
       "  0.06498996168375015,\n",
       "  0.06798090785741806,\n",
       "  0.058200206607580185,\n",
       "  0.06258579343557358,\n",
       "  0.058797769248485565,\n",
       "  0.06308655440807343,\n",
       "  0.06578738242387772],\n",
       " 'val_accuracy': [0.9679999947547913,\n",
       "  0.9776666760444641,\n",
       "  0.9810000061988831,\n",
       "  0.984333336353302,\n",
       "  0.9803333282470703,\n",
       "  0.9860000014305115,\n",
       "  0.9829999804496765,\n",
       "  0.9833333492279053,\n",
       "  0.9800000190734863,\n",
       "  0.9826666712760925]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history_dict=history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'ro')\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['accuracy']\n",
    "val_loss_values = history_dict['val_accuracy']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'ro')\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras Single Class\n",
    "\n",
    "Now we'll make an example of a binary classification task using Keras.\n",
    "\n",
    "The dataset is hosted on [Kaggle](https://www.kaggle.com/) and it's the [Promotion Response for a New Product](https://www.kaggle.com/regivm/promotion-response-and-target-datasets/version/1).\n",
    "\n",
    "The description of th dataset is the following:\n",
    "\n",
    "*The context of this business problem is new product introduction. A business organization developed a new product and promoted this to its existing customers. Initially it chose a sample of customers for promotion and the response information is available in the 'promoted' dataset. The organization is interested in building a model to select the best customers for contacting from the pool of customers not contacted ('target' dataset).*\n",
    "\n",
    "and the columns are:\n",
    "\n",
    "  - customer_id\n",
    "  - **res** (what we want to predict)\n",
    "  - card_tenure\n",
    "  - risk_score\n",
    "  - num_promoted\n",
    "  - avg_bal\n",
    "  - geo_group\n",
    "  - res_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python Class \n",
    "\n",
    "To learn something new, we'll make the code of this model using Python classes.\n",
    "\n",
    "A **Class** is a blueprint for an object, that can contain variables and functions (called method).\n",
    "\n",
    "The definition on the Python website is:\n",
    "\n",
    "_\"Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by its class) for modifying its state.\"_\n",
    "\n",
    "The characteristics of a Python Class are:\n",
    "\n",
    "  - Class (note also the usage of upper and lower letters)  \n",
    "  - `__init__` function (very often)\n",
    "  - Properties \n",
    "  - Methods \n",
    "  - `self` parameter\n",
    "  \n",
    "\n",
    "Please note similarity of our class with all what we have used so far.\n",
    "\n",
    "While we are looking to python classes we can also introduce two other usefull things:\n",
    "  - `kargs`\n",
    "  - logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:19,148 : INFO : INIZIALIZATION OF LOADDATA\n",
      "2020-10-31 18:49:19,150 : INFO : READING data/target.csv\n",
      "2020-10-31 18:49:19,306 : INFO : LOADED DATASET WITH SHAPE (110000, 8), COLUMUNS Index(['customer_id', 'card_tenure', 'risk_score', 'num_promoted', 'avg_bal',\n",
      "       'geo_group', 'res_type', 'Unnamed: 7'],\n",
      "      dtype='object') AND TYPES customer_id       object\n",
      "card_tenure      float64\n",
      "risk_score         int64\n",
      "num_promoted       int64\n",
      "avg_bal         category\n",
      "geo_group       category\n",
      "res_type        category\n",
      "Unnamed: 7       float64\n",
      "dtype: object\n",
      "2020-10-31 18:49:19,342 : INFO : READING data/promoted.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LoadData'>\n",
      "After reading          card_tenure     risk_score   num_promoted  Unnamed: 7\n",
      "count  107792.000000  110000.000000  110000.000000         0.0\n",
      "mean      138.956564     655.571482       0.006782         NaN\n",
      "std        67.433081      81.252328       0.082183         NaN\n",
      "min        12.000000     520.000000       0.000000         NaN\n",
      "25%        91.000000     600.000000       0.000000         NaN\n",
      "50%       135.000000     678.000000       0.000000         NaN\n",
      "75%       179.000000     720.000000       0.000000         NaN\n",
      "max       641.000000     760.000000       2.000000         NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:19,377 : INFO : LOADED DATASET WITH SHAPE (25000, 8), COLUMUNS Index(['customer_id', 'resp', 'card_tenure', 'risk_score', 'num_promoted',\n",
      "       'avg_bal', 'geo_group', 'res_type'],\n",
      "      dtype='object') AND TYPES customer_id       object\n",
      "resp               int64\n",
      "card_tenure      float64\n",
      "risk_score         int64\n",
      "num_promoted       int64\n",
      "avg_bal         category\n",
      "geo_group       category\n",
      "res_type        category\n",
      "dtype: object\n",
      "2020-10-31 18:49:19,399 : INFO : REMOVING ROWS WITH NA\n",
      "2020-10-31 18:49:19,400 : INFO : NROWS BEFORE REMOVING NA 25000\n",
      "2020-10-31 18:49:19,410 : INFO : NROWS AFTER REMOVING NA 22400\n",
      "2020-10-31 18:49:19,411 : INFO : CONSIDERING LEVELS FOR CATEGORICAL COLUMNS\n",
      "2020-10-31 18:49:19,415 : INFO : SCALING OF NUMERIC COLUMNS\n",
      "2020-10-31 18:49:19,430 : INFO : INIZIALIZATION OF CreateNN\n",
      "2020-10-31 18:49:19,431 : INFO : DEFINITION OF THE MODEL\n",
      "2020-10-31 18:49:19,468 : INFO : COMPILATION OF THE MODEL\n",
      "2020-10-31 18:49:19,478 : INFO : EVALUATION OF THE MODEL\n",
      "2020-10-31 18:49:19,478 : INFO : START OF THE CROSS VALIDATION\n",
      "2020-10-31 18:49:19,483 : INFO : WORKING ON FOLD 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reading                resp   card_tenure    risk_score  num_promoted\n",
      "count  25000.000000  24515.000000  25000.000000  25000.000000\n",
      "mean       0.068640    139.491617    655.091680      0.007000\n",
      "std        0.252846     66.998010     81.315116      0.083374\n",
      "min        0.000000      0.000000    520.000000      0.000000\n",
      "25%        0.000000     95.000000    599.000000      0.000000\n",
      "50%        0.000000    135.000000    677.000000      0.000000\n",
      "75%        0.000000    179.000000    719.000000      0.000000\n",
      "max        1.000000    641.000000    760.000000      1.000000\n",
      "SHAPE OF dfEnc AFTER ALL: 22400 X 7\n",
      "AFTER PREPROCESSING dfEnc HAS COLUMUNS Index(['resp', 'card_tenure', 'risk_score', 'num_promoted', 'avg_bal',\n",
      "       'geo_group', 'res_type'],\n",
      "      dtype='object') AND TYPES resp              int64\n",
      "card_tenure     float64\n",
      "risk_score      float64\n",
      "num_promoted    float64\n",
      "avg_bal           int16\n",
      "geo_group          int8\n",
      "res_type           int8\n",
      "dtype: object\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 25)                200       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 527\n",
      "Trainable params: 527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "train set [ 4474  4481  4482 ... 22397 22398 22399]\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 35.2254 - accuracy: 0.0723\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.0051 - accuracy: 0.7388\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.6658 - accuracy: 0.9314\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4071 - accuracy: 0.9314\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9029 - accuracy: 0.9314\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:21,528 : INFO : WORKING ON FOLD 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set [    0     1     2 ... 22397 22398 22399]\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.9309\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.9304\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.9314\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2953 - accuracy: 0.9314\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.9314\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:22,742 : INFO : WORKING ON FOLD 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set [    0     1     2 ... 22397 22398 22399]\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.9314\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.9314\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.9314\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.9314\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9314\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:23,796 : INFO : WORKING ON FOLD 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set [    0     1     2 ... 22397 22398 22399]\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.9314\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.9314\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.2660 - accuracy: 0.9314\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2580 - accuracy: 0.9314\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2490 - accuracy: 0.9314\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:25,339 : INFO : WORKING ON FOLD 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set [    0     1     2 ... 18004 18008 18031]\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.9315\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.9315\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9315\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2491 - accuracy: 0.9315\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2513 - accuracy: 0.9315\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 18:49:26,637 : INFO : EVALUATION COMPLETED\n",
      "2020-10-31 18:49:26,639 : INFO : FOR THE ACTUAL MODEL THE RESULTS OF accuracy IS: 0.93%+/-0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import advanced_activations\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 5\n",
    "batch_size = 1000\n",
    "n_fold = 5\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 25 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "#num_input = 6 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 1 # MNIST total classes (0-9 digits)\n",
    "\n",
    "trainFile = 'promoted.csv'\n",
    "predFile = 'target.csv'\n",
    "\n",
    "#\n",
    "activationFun = 'relu'\n",
    "#activationFun = 'softmax'\n",
    "\n",
    "testOneHot = False\n",
    "\n",
    "class LoadData:\n",
    "    def __init__(self,**kargs):\n",
    "        self.path = 'data'\n",
    "        self.trainFile = kargs['tr']\n",
    "        self.colList = ['avg_bal','geo_group', 'res_type']\n",
    "        \n",
    "    def readFiles(self,fileName):\n",
    "        fullPath = os.path.join(self.path,fileName)\n",
    "        logger.info('READING %s',fullPath)\n",
    "        df = pd.read_csv(fullPath,sep=',',dtype={'avg_bal':'category', 'geo_group':'category', 'res_type':'category',})#dtype={'avg_bal':'category', 'geo_group':'category', 'res_type':'category',}\n",
    "        logger.info('LOADED DATASET WITH SHAPE %s, COLUMUNS %s AND TYPES %s',str(df.shape),str(df.columns),str(df.dtypes))\n",
    "        print('After reading',df.describe())\n",
    "        return df\n",
    "    \n",
    "    def useOneHot(self,df):\n",
    "        print('SHAPE OF DF: %i X %i'%(df.shape[0],df.shape[1]))\n",
    "        df2Enc = df.loc[:,self.colList]\n",
    "        print('SHAPE OF DF2ENC: %i X %i'%(df2Enc.shape[0],df2Enc.shape[1]))\n",
    "        enc = OneHotEncoder()\n",
    "        dfEnc = enc.fit_transform(df2Enc)\n",
    "        print('SHAPE OF DFENC: %i X %i'%(dfEnc.shape[0],dfEnc.shape[1]))\n",
    "        print(type(dfEnc))\n",
    "        dfEnc = pd.DataFrame(dfEnc.toarray())\n",
    "        print('SHAPE OF DFENC: %i X %i'%(dfEnc.shape[0],dfEnc.shape[1]))\n",
    "        #df.drop(columns=self.colList,inplace=True)\n",
    "        return dfEnc\n",
    "        \n",
    "        \n",
    "    def prepareTrain(self):\n",
    "        dfTrain = self.readFiles(self.trainFile)\n",
    "        logger.info('REMOVING ROWS WITH NA')\n",
    "        logger.info('NROWS BEFORE REMOVING NA %i',dfTrain.shape[0])\n",
    "        dfTrain.dropna(inplace=True)\n",
    "        dfTrain.drop(columns=['customer_id'],inplace=True)\n",
    "        logger.info('NROWS AFTER REMOVING NA %i',dfTrain.shape[0])\n",
    "        Y_train = dfTrain.loc[:,'resp']\n",
    "        logger.info('CONSIDERING LEVELS FOR CATEGORICAL COLUMNS')\n",
    "        if testOneHot:\n",
    "            logger.info('Using OHE')\n",
    "            dfEnc = self.useOneHot(dfTrain)\n",
    "            print('SHAPE OF X_train: %i X %i'%(dfEnc.shape[0],dfEnc.shape[1]))\n",
    "        else:\n",
    "            for curCol in self.colList:\n",
    "                dfTrain[curCol] = dfTrain[curCol].cat.codes\n",
    "                dfEnc = dfTrain.copy()\n",
    "        logger.info('SCALING OF NUMERIC COLUMNS')\n",
    "        mmscaler = preprocessing.MinMaxScaler()\n",
    "        for curCol in ['card_tenure', 'risk_score', 'num_promoted']:\n",
    "            curFeat = mmscaler.fit_transform(dfTrain[[curCol]])  \n",
    "            dfEnc[curCol] = curFeat.reshape(-1,1)\n",
    "        print('SHAPE OF dfEnc AFTER ALL: %i X %i'%(dfEnc.shape[0],dfEnc.shape[1]))\n",
    "        print('AFTER PREPROCESSING dfEnc HAS COLUMUNS %s AND TYPES %s'%(str(dfEnc.columns),str(dfEnc.dtypes)))\n",
    "        return dfEnc, Y_train\n",
    "\n",
    "class CreateNN:\n",
    "    def __init__(self,**kargs):\n",
    "        self.X_train = kargs['xt']\n",
    "        self.Y_train = kargs['yt']\n",
    "        self.kFold = kargs['kf']\n",
    "        self.i = 1\n",
    "        self.num_input = self.X_train.shape[1]\n",
    "        \n",
    "    def modelDefinition(self):\n",
    "        logger.info('DEFINITION OF THE MODEL')\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(self.num_input, input_dim = self.num_input,activation=activationFun))\n",
    "        self.model.add(Dense(n_hidden_1,activation = activationFun))\n",
    "        self.model.add(Dense(n_hidden_2,activation = activationFun))\n",
    "        self.model.add(Dense(num_classes,activation = 'sigmoid'))\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def modelCompile(self):\n",
    "        logger.info('COMPILATION OF THE MODEL')\n",
    "        adam = Adam(lr = learning_rate)\n",
    "        self.model.compile(loss = 'binary_crossentropy', optimizer = adam,metrics = ['accuracy'])\n",
    "        \n",
    "    def modelEval(self):\n",
    "        logger.info('EVALUATION OF THE MODEL')\n",
    "        totalScores = list()\n",
    "        logger.info('START OF THE CROSS VALIDATION')\n",
    "        for train,test in self.kFold.split(self.X_train, self.Y_train):\n",
    "            logger.info('WORKING ON FOLD %i',self.i)\n",
    "            print('train set',train)\n",
    "            history = self.model.fit(self.X_train.iloc[train], self.Y_train.iloc[train],\n",
    "                                     epochs=num_steps, \n",
    "                                     batch_size = batch_size) #validation_data=(self.X_train.iloc[test], self.Y_train.iloc[test])\n",
    "            scores = self.model.evaluate(self.X_train.iloc[test], self.Y_train.iloc[test])\n",
    "            totalScores.append(scores[1])\n",
    "            self.i += 1\n",
    "        return history, self.model, totalScores\n",
    "\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    #Inizialization of the class LoadData \n",
    "    logger.info('INIZIALIZATION OF LOADDATA')\n",
    "    ld = LoadData(tr=trainFile)\n",
    "    print(type(ld))\n",
    "    df2Pred = ld.readFiles(predFile)\n",
    "    X_train, Y_train = ld.prepareTrain()\n",
    "    kfold = StratifiedKFold(n_splits=n_fold)\n",
    "    logger.info('INIZIALIZATION OF CreateNN')\n",
    "    cnn = CreateNN(xt=X_train,yt=Y_train,kf=kfold)\n",
    "    cnn.modelDefinition()\n",
    "    cnn.modelCompile()\n",
    "    history, model, totalScores = cnn.modelEval() \n",
    "    logger.info('EVALUATION COMPLETED')\n",
    "    logger.info(\"FOR THE ACTUAL MODEL THE RESULTS OF %s IS: %.2f%%+/-%.2f%%\" % (model.metrics_names[1], np.mean(totalScores),np.std(totalScores)))\n",
    "    return X_train,Y_train, history,totalScores\n",
    "    \n",
    "X_train,Y_train, history,totalScores = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise Model\n",
    "\n",
    "Try to understand the best parameters for the above model using what we have learned in this lesson (hint: look if the model is overfitting).\n",
    "\n",
    "After the definition of a good model, try to make the prediction over the pred set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Class\n",
    "\n",
    "Try to re-write the first Keras Model using a *Class* approach.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom model\n",
    "\n",
    "The models that we have built in the previous examples are made using the **Sequantial model**: `from keras.models import Sequential`.\n",
    "\n",
    "The sequential model is the standard to create a network with a sequence of layers,one after the other.\n",
    "\n",
    "Aside from that model, Keras give us the possibility to create networks with others layout ([more info about models](https://keras.io/models/about-keras-models/)).\n",
    "\n",
    "This is done with the **functional API** ([more about functional API](https://keras.io/models/model/)).\n",
    "\n",
    "The functional API usable with this import `from keras.models import Model`.\n",
    "\n",
    "**NOTE:** with this kinf of model we are working directly with tensors ([wiki tensor](https://en.wikipedia.org/wiki/Tensor)). \n",
    "\n",
    "In this case we want to build a model that \"simulate\" a linear regression using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print(tf.keras.__version__,keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "preds = Dense(1,activation='linear')(inputs)\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = x*2\n",
    "x_test = x*10\n",
    "y_test = x_test*2\n",
    "\n",
    "model = Model(inputs=inputs,outputs=preds)\n",
    "sgd=keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
    "model.fit(x,y, batch_size=1, epochs=30, shuffle=False)\n",
    "#model.predict(x_test).shape\n",
    "res = pd.DataFrame({'pred':model.predict(x_test)[:,0],'real':y_test})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(model.predict(x_test))\n",
    "model.summary()\n",
    "type(inputs)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
